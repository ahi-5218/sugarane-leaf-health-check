# -*- coding: utf-8 -*-
"""SugarcaneLeafDieseaseDetectionUsingDenseNet201ofKeras.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sD8dUKph3gAa-P6OEGMs4__Op032E1vI

---



# Sugarcane Leaf Disease Detection
The model is capable of performing Image Classification for:
1.   Healthy
2.   Red Rot
1.   Red Rust

**Dataset:**<br>
*Healthy leaves: 500 Images*<br>
*Red Rot leaves: 500 Images*<br>
*Red Rust leaves: 510 Images*<br>
*Total Images: 1565 Images*


---
"""

from google.colab import drive
drive.mount('/content/drive')

"""#### Importing Libraries"""

#Data Visualization
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import os
import seaborn as sns

#Sharpening of images
from skimage.io import imshow, imread
from skimage.color import rgb2yuv, rgb2hsv, rgb2gray, yuv2rgb, hsv2rgb
from scipy.signal import convolve2d

#Preprocessing of Images
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.preprocessing.image import img_to_array
from tensorflow.keras.preprocessing.image import load_img
from tensorflow.keras.utils import to_categorical
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split

#Buliding Model
from tensorflow.keras.layers import AveragePooling2D
from tensorflow.keras.layers import Dropout
from tensorflow.keras.layers import Flatten
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Input
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam

#Accuracy
from sklearn.metrics import classification_report

data_dir = '/content/drive/MyDrive/miniprojectSugarcane/Dataset'
categories = os.listdir(data_dir)

categories=sorted(categories)
print(categories)

labels=[i for i in range(len(categories))]
labels

"""#### Making a dictionary with Classes as Keys and Indices as Values"""

label_dict=dict(zip(categories, labels))
label_dict

data_list=[] #data_list- storing the images
labels_list=[] #label_list - storing the class labels

data1="/content/drive/MyDrive/miniprojectSugarcane/Dataset/Healthy"
data2="/content/drive/MyDrive/miniprojectSugarcane/Dataset/RedRot"
data3="/content/drive/MyDrive/miniprojectSugarcane/Dataset/RedRust"
count_healthy=0
count_redrot=0
count_redrust=0

for i in os.listdir(data1):
        img_path=os.path.join(data1, i)
        count_healthy=count_healthy+1

for i in os.listdir(data2):
        img_path=os.path.join(data2, i)
        count_redrot=count_redrot+1

for i in os.listdir(data3):
        img_path=os.path.join(data3, i)
        count_redrust=count_redrust+1

count_healthy,count_redrot,count_redrust

fig = plt.figure(figsize = (10, 5))
classes=["Healthy","RedRot", "RedRust"]
values=[count_healthy,count_redrot,count_redrust]
#creating the bar plot
plt.bar(classes, values, color ='blue',
        width = 0.4)

plt.xlabel("Classes")
plt.ylabel("Number of Images")
plt.show()

"""#### Defining a Sharpen Filter"""

sharpen = np.array([[0, -1, 0],
                    [-1, 5, -1],
                    [0, -1, 0]])

og_image = imread(data_dir+'/RedRot/redrot (440).jpeg')
imshow(og_image);

def multi_convolver(image, kernel, iterations):
    for i in range(iterations):
        image = convolve2d(image, kernel, 'same', boundary = 'fill',
                           fillvalue = 0)
    return image

def convolver_rgb(image, kernel, iterations = 1):
    img_yuv = rgb2yuv(image)
    img_yuv[:,:,0] = multi_convolver(img_yuv[:,:,0], kernel,
                                     iterations)
    final_image = yuv2rgb(img_yuv)
    return final_image

final_image = convolver_rgb(og_image, sharpen, iterations = 1)
imshow(final_image);

"""#### Image Preprocessing
1.   Resizing to 224,224
2.   Sharpening


"""

from PIL import Image
import os
import numpy as np

# Assuming data_dir, categories, sharpen, and label_dict are defined elsewhere

data_list = []  # Initialize data_list as a list
labels_list = [] # Initialize labels_list as a list

for i in categories:
    folder_path=os.path.join(data_dir, i) #path to each disease folder
    img_names=os.listdir(folder_path)   #all images in each disease folder
    for img_name in img_names:
        img_path=os.path.join(folder_path, img_name)
        # Check if the path is a file before trying to open it with PIL
        if os.path.isfile(img_path):
          if(img_path=='/content/drive/MyDrive/miniprojectSugarcane/Dataset/Healthy' or img_path=='/content/drive/MyDrive/miniprojectSugarcane/Dataset/RedRot' or img_path=='/content/drive/MyDrive/miniprojectSugarcane/Dataset/RedRust'):
            continue
          img = Image.open(img_path)
          img = img.resize((224,224))
          img = np.array(img)
          img = convolver_rgb(img, sharpen, iterations = 1)
          data_list.append(img)
          labels_list.append(label_dict[i]) # append to the list labels_list

data_list[0].shape

lb = LabelEncoder()
labels_list = lb.fit_transform(labels_list)
labels_list = to_categorical(labels_list)

data = np.array(data_list)
labels = np.array(labels_list)
print("Done")
print(data.shape)

"""#### Visualizing Images in the Dataset after Preprocessing"""

plt.figure(figsize=(10,10))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(data[np.random.randint(224)], cmap=plt.cm.binary)

plt.show()

"""#### Image Augmentation"""

aug = ImageDataGenerator(
	rotation_range=20,
	zoom_range=0.15,
	width_shift_range=0.2,
	height_shift_range=0.2,
	shear_range=0.15,
	horizontal_flip=True,
	fill_mode="nearest")

"""#### Splitting Dataset into Train and Test Sets"""

(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.20, stratify=labels, random_state=42)

print( trainX.shape, testX.shape, trainY.shape, testY.shape)

"""#### The model"""

from keras.applications.densenet import DenseNet201
from tensorflow.keras.models import Sequential,Model
from tensorflow.keras.layers import Dense ,Dropout
from keras.layers import Input

base_model = DenseNet201(include_top=False,
                         input_shape=(224,224,3),
                         weights='imagenet',
                         pooling="avg"
                     )

from tensorflow.keras.regularizers import l2

base_model.trainable = False
image_input = Input(shape=(224, 224, 3))

x = base_model(image_input,training = False)

x = Dense(256,activation = "relu")(x)
x = Dropout(0.2)(x)

x = Dense(128,activation = "relu")(x)
x = Dropout(0.2)(x)

image_output = Dense(3,kernel_regularizer=l2(0.01),activation="softmax")(x) #output layer
#kernel Regulariser- SVM

model = Model(image_input,image_output)
model.compile(optimizer="adam",loss="squared_hinge",metrics=["accuracy"])
#loss function is square hinged- SVM

#from tensorflow.keras.utils import plot_model

"""
!apt install graphviz
!pip install pydot
!pip install graphviz"""

#plot_model(base_model, to_file = 'Densenet.png', show_shapes = True, show_layer_names = True)

"""#### Training the Model"""

BS=32
EPOCHS=10

"""history = model.fit(
	aug.flow(trainX, trainY, batch_size=BS),
	steps_per_epoch=len(trainX) // BS,
	validation_data=(testX, testY),
	validation_steps=len(testX) // BS,
	epochs=EPOCHS)"""

history = model.fit(
    aug.flow(trainX, trainY, batch_size=BS),
    steps_per_epoch=len(trainX) // BS,
    epochs=EPOCHS)

print("[INFO] evaluating network...")
predIdxs = model.predict(testX, batch_size=BS)

# for each image in the testing set we need to find the index of the
# label with corresponding largest predicted probability
predIdxs = np.argmax(predIdxs, axis=1)

# show a nicely formatted classification report
print(classification_report(testY.argmax(axis=1), predIdxs))

from sklearn.metrics import confusion_matrix

cm = confusion_matrix(testY.argmax(axis=1), predIdxs)


cm_df = pd.DataFrame(cm,
                     index = ['Healthy','RedRot','RedRust'],
                     columns = ['Healthy','RedRot','RedRust'])
plt.figure(figsize=(5,4))
sns.heatmap(cm_df, annot=True, cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.ylabel('Actal Values')
plt.xlabel('Predicted Values')
plt.show()

"""import matplotlib.pyplot as plt
plt.figure(0)

plt.plot(history.history['accuracy'], label='training accuracy')
plt.plot(history.history['val_accuracy'], label='val accuracy')
plt.title('Accuracy')
plt.xlabel('epochs')
plt.ylabel('accuracy')
plt.legend()
plt.show()

plt.figure(1)
plt.plot(history.history['loss'], label='training loss')
plt.plot(history.history['val_loss'], label='val loss')
plt.title('Loss')
plt.xlabel('epochs')
plt.ylabel('loss')
plt.legend()
plt.show()

#### Making the Predictions
"""

from keras.preprocessing import image

img = image.load_img("/content/drive/MyDrive/miniprojectSugarcane/DatasetSLeafTestImgs/healthy (501).jpeg", target_size=(224,224))
x = image.img_to_array(img)
x=x/255
img = convolver_rgb(img, sharpen, iterations = 1)
x=x.reshape(224,224,3)
x = np.expand_dims(x, axis=0)


predi=model.predict(x)
print(predi)
classes_x=np.argmax(predi)
print(classes_x)

classes=["Healthy","Red Rot", "Red Rust"]
prediction_label=prediction_label=classes[classes_x]
if(prediction_label=="Healthy"):
  print("It is a Healthy Leaf")
else:
  print("Disease detected: "+prediction_label)

"""#### Saving the Model"""

model.save("SugarDenseNetSVM_Model.h5")

import pickle

##dump the model into a file
with open("sugarDenseNetSVM_Model.h5", 'wb') as f_out:
    pickle.dump(model, f_out) # write final_model in .bin file
    f_out.close()  # close the file

##loading the model from the saved file
with open('sugarDenseNetSVM_Model.h5', 'rb') as f_in:
    model = pickle.load(f_in)

